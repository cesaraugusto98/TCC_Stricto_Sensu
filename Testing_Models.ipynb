{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Testing Multiple Models since our dataset is ready"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras import Model \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "\n",
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#Setting Global Variables\n",
    "FINAL_PATH = \"dataset_final//imagens//\"\n",
    "\n",
    "TRAIN_PATH = \"dataset_final//train//\"\n",
    "\n",
    "TEST_PATH = \"dataset_final//test//\"\n",
    "\n",
    "SIZE=224"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "pele_df = pd.read_csv('dataset_final/classificacao_dataset.csv')\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(pele_df['type'])\n",
    "LabelEncoder()\n",
    "print('label 0 é igual á ' + list(le.classes_)[0])\n",
    "print('label 1 é igual á ' + list(le.classes_)[1])\n",
    "\n",
    "pele_df['label'] = le.transform(pele_df[\"type\"]) \n",
    "\n",
    "\n",
    "print(pele_df['label'].value_counts())\n",
    "\n",
    "print(pele_df.head())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "label 0 é igual á mel\n",
      "label 1 é igual á nv\n",
      "1    6805\n",
      "0    1183\n",
      "Name: label, dtype: int64\n",
      "   Unnamed: 0      image_id type  label\n",
      "0           0  ISIC_0024698   nv      1\n",
      "1           1  ISIC_0024693   nv      1\n",
      "2           2  ISIC_0025964  mel      0\n",
      "3           3  ISIC_0030623  mel      0\n",
      "4           4  ISIC_0027190  mel      0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "pele_df_final = pele_df.copy()\n",
    "\n",
    "image_path = {os.path.splitext(os.path.basename(x))[0]: x\n",
    "                     for x in glob(os.path.join('dataset_final', '*', '*.jpg'))}\n",
    "\n",
    "#Definindo o diretório como uma nova coluna\n",
    "pele_df_final['path'] = pele_df['image_id'].map(image_path.get)\n",
    "\n",
    "#Usar o dataframe completo estava levando muito tempo, portanto tive de quebra-lo num fração menor, ainda com mais de 2000 linhas\n",
    "pele_df_final_frac = pele_df_final.sample(frac=0.35)\n",
    "\n",
    "print(pele_df_final_frac['type'].value_counts())\n",
    "\n",
    "X = pele_df_final_frac['path']\n",
    "Y = pele_df_final_frac['type'] #Assign label values to Y"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "nv     2395\n",
      "mel     401\n",
      "Name: type, dtype: int64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "print(f'Valores únicos para Y: {list(set(Y))}')\n",
    "\n",
    "x_train_auto, x_test_auto, y_train_auto, y_test_auto = train_test_split(X, Y, test_size=0.20, random_state=42)\n",
    "\n",
    "print(f'x_train_auto: {x_train_auto[0:5]}')\n",
    "print(f'x_test_auto: {x_test_auto[0:5]}')\n",
    "print(f'y_train_auto: {y_train_auto[0:5]}')\n",
    "print(f'y_test_auto: {y_test_auto[0:5]}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Valores únicos para Y: ['nv', 'mel']\n",
      "x_train_auto: 972     dataset_final/imagens/ISIC_0028567.jpg\n",
      "7863          dataset_final/imagens/586355.jpg\n",
      "7838          dataset_final/imagens/363475.jpg\n",
      "4873    dataset_final/imagens/ISIC_0027264.jpg\n",
      "1461    dataset_final/imagens/ISIC_0028539.jpg\n",
      "Name: path, dtype: object\n",
      "x_test_auto: 6180    dataset_final/imagens/ISIC_0033390.jpg\n",
      "4795    dataset_final/imagens/ISIC_0028417.jpg\n",
      "7595    dataset_final/imagens/ISIC_0033247.jpg\n",
      "207     dataset_final/imagens/ISIC_0024496.jpg\n",
      "3513    dataset_final/imagens/ISIC_0026063.jpg\n",
      "Name: path, dtype: object\n",
      "y_train_auto: 972     mel\n",
      "7863    mel\n",
      "7838    mel\n",
      "4873     nv\n",
      "1461     nv\n",
      "Name: type, dtype: object\n",
      "y_test_auto: 6180     nv\n",
      "4795     nv\n",
      "7595     nv\n",
      "207     mel\n",
      "3513     nv\n",
      "Name: type, dtype: object\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df_train = pd.DataFrame(columns=['image_path','type'])\n",
    "df_train['image_path'] = x_train_auto\n",
    "df_train['type'] = y_train_auto\n",
    "\n",
    "df_test = pd.DataFrame(columns=['image_path','type'])\n",
    "df_test['image_path'] = x_test_auto\n",
    "df_test['type'] = y_test_auto"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "#Creating a directory for Train \n",
    "for n, row in df_train.iterrows():\n",
    "    if row['type']=='mel':\n",
    "        shutil.copy2(row['image_path'], TRAIN_PATH + 'mel//')\n",
    "    else: \n",
    "        shutil.copy2(row['image_path'], TRAIN_PATH+ 'nv//')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "#Creating a directory for Test\n",
    "for n, row in df_test.iterrows():\n",
    "    if row['type']=='mel':\n",
    "        shutil.copy2(row['image_path'], TEST_PATH + 'mel//')\n",
    "    else: \n",
    "        shutil.copy2(row['image_path'], TEST_PATH+ 'nv//')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing VGG-16"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "SIZE = 224"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Image Augmentation\n",
    "\n",
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255.,rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator( rescale = 1.0/255. )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Training and Validation Sets\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(TRAIN_PATH, batch_size = 20, class_mode = 'binary', target_size = (SIZE, SIZE))\n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator = test_datagen.flow_from_directory(TEST_PATH,  batch_size = 20, class_mode = 'binary', target_size = (SIZE, SIZE))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 2236 images belonging to 2 classes.\n",
      "Found 560 images belonging to 2 classes.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Loading the Base Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "base_model = VGG16(input_shape = (SIZE, SIZE, 3), # Shape of our images\n",
    "include_top = True, # Leave out the last fully connected layer\n",
    "weights = 'imagenet')\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    print(layer)\n",
    "    layer.trainable = False"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2022-03-28 19:52:34.491616: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Compile and Fit\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "print(layers.Flatten()(base_model.output))\n",
    "x = layers.Flatten()(base_model.output)\n",
    "\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.5\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Add a final sigmoid layer with 1 node for classification output\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.models.Model(base_model.input, x)\n",
    "\n",
    "model.compile(optimizer = RMSprop(learning_rate=0.0001), loss = 'binary_crossentropy',metrics = ['acc'])"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "The name \"flatten\" is used 2 times in the model. All layer names should be unique.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/n0/r90d5h151sq9vq_khl6kf7v40000gn/T/ipykernel_5412/989228172.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRMSprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m                   for t in tf.nest.flatten(inputs)]):\n\u001b[1;32m    145\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctional_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone_graph_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m     nodes, nodes_by_depth, layers, _ = _map_graph_network(\n\u001b[0m\u001b[1;32m    230\u001b[0m         self.inputs, self.outputs)\n\u001b[1;32m    231\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m       raise ValueError(\n\u001b[0m\u001b[1;32m   1050\u001b[0m           \u001b[0;34mf'The name \"{name}\" is used {all_names.count(name)} '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           'times in the model. All layer names should be unique.')\n",
      "\u001b[0;31mValueError\u001b[0m: The name \"flatten\" is used 2 times in the model. All layer names should be unique."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vgghist = model.fit(train_generator, validation_data = validation_generator, batch_size=20, steps_per_epoch = 20, epochs = 8)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing Inception"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "SIZE = 150"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Data Augmentation\n",
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255., rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2,shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator( rescale = 1.0/255. )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Training and Validation Generators\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(TRAIN_PATH, batch_size = 20, class_mode = 'binary', target_size = (SIZE, SIZE))\n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator = test_datagen.flow_from_directory(TEST_PATH,  batch_size = 20, class_mode = 'binary', target_size = (SIZE, SIZE))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 2236 images belonging to 2 classes.\n",
      "Found 560 images belonging to 2 classes.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Loading the Base Model\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "base_model = InceptionV3(input_shape = (SIZE, SIZE, 3), include_top = False, weights = 'imagenet')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Compile and Fit\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "x = layers.Flatten()(base_model.output)\n",
    "x = layers.Dense(18432, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "\n",
    "# Add a final sigmoid layer with 1 node for classification output\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.models.Model(base_model.input, x)\n",
    "\n",
    "model.compile(optimizer = RMSprop(learning_rate=0.0001), loss = 'binary_crossentropy', metrics = ['acc'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "inc_history = model.fit(train_generator, validation_data = validation_generator, batch_size=20, steps_per_epoch = 20, epochs = 8)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/8\n",
      "20/20 [==============================] - 424s 19s/step - loss: 5.5184 - acc: 0.7250 - val_loss: 1.0225 - val_acc: 0.8339\n",
      "Epoch 2/8\n",
      "20/20 [==============================] - 254s 13s/step - loss: 1.6929 - acc: 0.8075 - val_loss: 2.7590 - val_acc: 0.8304\n",
      "Epoch 3/8\n",
      "20/20 [==============================] - 220s 11s/step - loss: 1.1718 - acc: 0.8525 - val_loss: 1.2351 - val_acc: 0.6732\n",
      "Epoch 4/8\n",
      "20/20 [==============================] - 837s 44s/step - loss: 1.6155 - acc: 0.8200 - val_loss: 0.7700 - val_acc: 0.8321\n",
      "Epoch 5/8\n",
      "20/20 [==============================] - 190s 9s/step - loss: 1.0785 - acc: 0.8225 - val_loss: 0.5307 - val_acc: 0.8321\n",
      "Epoch 6/8\n",
      "20/20 [==============================] - 208s 10s/step - loss: 1.1973 - acc: 0.8025 - val_loss: 0.5526 - val_acc: 0.8196\n",
      "Epoch 7/8\n",
      "20/20 [==============================] - 342s 18s/step - loss: 1.5651 - acc: 0.7675 - val_loss: 0.6969 - val_acc: 0.7679\n",
      "Epoch 8/8\n",
      "20/20 [==============================] - 210s 10s/step - loss: 0.8909 - acc: 0.8225 - val_loss: 0.5629 - val_acc: 0.8518\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing ResNet50"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "SIZE=224"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Data Augmentation and Generators\n",
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255., rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(TRAIN_PATH, batch_size = 20, class_mode = 'binary', target_size = (SIZE, SIZE))\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(TEST_PATH, batch_size = 20, class_mode = 'binary', target_size = (SIZE, SIZE))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Import the base model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "base_model = ResNet50(input_shape=(SIZE, SIZE,3), include_top=False, weights=\"imagenet\")\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Build and Compile the Model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten\n",
    "\n",
    "base_model = Sequential()\n",
    "base_model.add(ResNet50(include_top=False, weights='imagenet', pooling='max'))\n",
    "base_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#opt = keras.optimizer_v2.gradient_descent.SGD(learning_rate=0.0001)\n",
    "base_model.compile(optimizer = 'SGD', loss = 'binary_crossentropy', metrics = ['acc'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "resnet_history = base_model.fit(train_generator, batch_size=20, validation_data = validation_generator, steps_per_epoch = 20, epochs = 8)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing EfficientNet"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install -U efficientnet_3D"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import efficientnet_3D.tfkeras as efn\n",
    "keras.utils.generic_utils = keras.utils.generic_utils"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "SIZE = 224"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Image Augmentation\n",
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255., rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(TRAIN_PATH, batch_size = 20, class_mode = 'binary', target_size = (SIZE, SIZE))\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(TEST_PATH, batch_size = 20, class_mode = 'binary', target_size = (SIZE, SIZE))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Loading the Base Model\n",
    "base_model = efn.EfficientNetB0(input_shape = (SIZE, SIZE, 3), include_top = False, weights = 'imagenet')\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Build the Model\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Add a final sigmoid layer with 1 node for classification output\n",
    "predictions = Dense(1, activation=\"sigmoid\")(x)\n",
    "model_final = Model(input = base_model.input, output = predictions)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Compile and Fit\n",
    "model_final.compile(optimizers.rmsprop(lr=0.0001, decay=1e-6),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "eff_history = model_final.fit_generator(train_generator, validation_data = validation_generator, steps_per_epoch = 20, epochs = 8)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing Random Forest Classifier"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "SIZE = 224"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "traceback": [
      "Error: Session cannot generate requests",
      "at w.executeCodeCell (/Users/cesaraugustosiqueirasantos/.vscode/extensions/ms-toolsai.jupyter-2021.8.1236758218/out/client/extension.js:90:327199)",
      "at w.execute (/Users/cesaraugustosiqueirasantos/.vscode/extensions/ms-toolsai.jupyter-2021.8.1236758218/out/client/extension.js:90:326520)",
      "at w.start (/Users/cesaraugustosiqueirasantos/.vscode/extensions/ms-toolsai.jupyter-2021.8.1236758218/out/client/extension.js:90:322336)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (/Users/cesaraugustosiqueirasantos/.vscode/extensions/ms-toolsai.jupyter-2021.8.1236758218/out/client/extension.js:90:336863)",
      "at async t.CellExecutionQueue.start (/Users/cesaraugustosiqueirasantos/.vscode/extensions/ms-toolsai.jupyter-2021.8.1236758218/out/client/extension.js:90:336403)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Data Augmentation and Generators\n",
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255., rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(TRAIN_PATH, batch_size = 20, class_mode = 'binary', target_size = (SIZE, SIZE))\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(TEST_PATH, batch_size = 20, class_mode = 'binary', target_size = (SIZE, SIZE))"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "traceback": [
      "Error: Session cannot generate requests",
      "at w.executeCodeCell (/Users/cesaraugustosiqueirasantos/.vscode/extensions/ms-toolsai.jupyter-2021.8.1236758218/out/client/extension.js:90:327199)",
      "at w.execute (/Users/cesaraugustosiqueirasantos/.vscode/extensions/ms-toolsai.jupyter-2021.8.1236758218/out/client/extension.js:90:326520)",
      "at w.start (/Users/cesaraugustosiqueirasantos/.vscode/extensions/ms-toolsai.jupyter-2021.8.1236758218/out/client/extension.js:90:322336)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (/Users/cesaraugustosiqueirasantos/.vscode/extensions/ms-toolsai.jupyter-2021.8.1236758218/out/client/extension.js:90:336863)",
      "at async t.CellExecutionQueue.start (/Users/cesaraugustosiqueirasantos/.vscode/extensions/ms-toolsai.jupyter-2021.8.1236758218/out/client/extension.js:90:336403)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "\n",
    "nsamples, nx, ny, nrgb = train_generator.shape\n",
    "x_train2 = train_generator.reshape((nsamples,nx*ny*nrgb))\n",
    "\n",
    "nsamples, nx, ny, nrgb = validation_generator.shape\n",
    "x_test2 = validation_generator.reshape((nsamples,nx*ny*nrgb))"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'DirectoryIterator' object has no attribute 'shape'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/n0/r90d5h151sq9vq_khl6kf7v40000gn/T/ipykernel_50958/3883297274.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnsamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mx_train2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnsamples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mny\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnrgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DirectoryIterator' object has no attribute 'shape'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model=RandomForestClassifier()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "model.fit(train_generator,validation_generator)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_pred=model.predict(x_test2)\n",
    "y_pred"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "traceback": [
      "Error: Session cannot generate requests",
      "at w.executeCodeCell (/Users/cesaraugustosiqueirasantos/.vscode/extensions/ms-toolsai.jupyter-2021.8.1236758218/out/client/extension.js:90:327199)",
      "at w.execute (/Users/cesaraugustosiqueirasantos/.vscode/extensions/ms-toolsai.jupyter-2021.8.1236758218/out/client/extension.js:90:326520)",
      "at w.start (/Users/cesaraugustosiqueirasantos/.vscode/extensions/ms-toolsai.jupyter-2021.8.1236758218/out/client/extension.js:90:322336)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (/Users/cesaraugustosiqueirasantos/.vscode/extensions/ms-toolsai.jupyter-2021.8.1236758218/out/client/extension.js:90:336863)",
      "at async t.CellExecutionQueue.start (/Users/cesaraugustosiqueirasantos/.vscode/extensions/ms-toolsai.jupyter-2021.8.1236758218/out/client/extension.js:90:336403)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "accuracy_score(y_pred,y_test)\n",
    "print(classification_report(y_pred,y_test))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}