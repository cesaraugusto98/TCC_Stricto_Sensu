{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# TCC Strictu Sensu - Skin Cancer detector"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Definição do Problema\n",
    "*Porque?* \n",
    "Cancer de pele é um dos cancer mais comuns na atualidade, se identificado no inicio, pode ser mais fácilmente tratado. A concientização é muito importante, devemos informar a população de modo geral e facilitar o teste, como por exemplo um simples carregar de uma foto em um aplicativo que já te retornará as chances de ser uma pinta ou mancha na pele se desenvolver em um cancer de pele.\n",
    "\n",
    "*Quem?* \n",
    "Este projeto visa ajudar todos que tiverem acesso a internet, ou smartphones, provendo uma maneira fácil de avaliar se pintas ou manchas na pele podem ser um cancer de pele em estágio inicial\n",
    "\n",
    "*Oque?*\n",
    "Um modelo de machine learning(mais precisamente deep learninng) que permitará que usuários externos testem pintas ou manchas, buscando por possiveis cancer de pele.\n",
    "\n",
    "*Quando?*\n",
    "O modelo deverá responder de maneira instantanea, ou mais próxima ao tempo real como 1 a 5 minutos. \n",
    "\n",
    "*Onde?*\n",
    "A principio através de input manual nesse projeto, mas no futuro usuários poderão carregar e testar imagens por um site ou applicativo de Smartphone."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Coleta dos Dados\n",
    "Segundo os requisitos desse projeto, duas bases de dados são requeridas. O tema desse projeto tem sido muito trabalhado por vários projetos ao longo dos últimos anos, porém existem apenas algumas bases muito populares, praticamente todas providas pela mesma fonte a ISIC que anualmente (desde 2016) tem lançado um desafio de Machine Learning e providenciado datasets com milhares de imagens com este tema. Entretando como exigência do projeto tive de buscar uma base de dados distinta e após pesquisa encontrei um dataset pequeno mas que me fornece imagens de Nevuas normais e melanoma. Afim de unir as bases precisei reduzir o escopo do dataset provido pela HAM10000 (Imagens colhidas pela ISIC em 2018), em apenas Nevuas normais ou melanomas."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "import os"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "FINAL_PATH = \"dataset_final//imagens//\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "path_HAM10000 = \"dataset_1//HAM10000_images//\"\n",
    "df_HAM10000_csv = \"dataset_1//HAM10000_metadata\"\n",
    "\n",
    "df_HAM10000_csv = pd.read_csv(df_HAM10000_csv)\n",
    "\n",
    "#Tamanho original\n",
    "print('Tamanho Original: ', df_HAM10000_csv.shape)\n",
    "\n",
    "#Filtrando apenas melanocytic nevi (begnigno) e melanoma(maligno), \n",
    "#o resto da base será desconsiderado para este estudo.\n",
    "df_HAM10000_csv_filtered=df_HAM10000_csv[(df_HAM10000_csv.dx == \"nv\") | (df_HAM10000_csv.dx == \"mel\")]\n",
    "\n",
    "#Tamanho após filtrado\n",
    "print('Tamanho após aplifcar o filtro: ', df_HAM10000_csv_filtered.shape)\n",
    "\n",
    "#Movendo os arquivos para Pasta Final\n",
    "for index, row in df_HAM10000_csv_filtered.iterrows(): \n",
    "    shutil.copy2(path_HAM10000 + row['image_id'] + '.jpg', FINAL_PATH)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_mednode = pd.DataFrame(columns=['image_id','type'])\n",
    "path_mednode = \"dataset_2//complete_mednode_dataset//\"\n",
    "\n",
    "for diretorio,subpasta, arquivos in os.walk(path_mednode):\n",
    "    if diretorio !=\"dataset_2//complete_mednode_dataset//\":\n",
    "        for arquivo in arquivos:\n",
    "            if 'melanoma' in diretorio:\n",
    "                df_mednode=df_mednode.append({'image_id': arquivo.replace('.jpg',''), 'type':'mel'}, ignore_index=True)\n",
    "                shutil.copy2(diretorio +'//'+ arquivo, FINAL_PATH)\n",
    "            elif 'naevus' in diretorio:\n",
    "                df_mednode=df_mednode.append({'image_id': arquivo.replace('.jpg',''), 'type':'nv'}, ignore_index=True)\n",
    "                shutil.copy2(diretorio +'//'+ arquivo, FINAL_PATH)\n",
    "        \n",
    "print(df_mednode.shape)\n",
    "df_mednode.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Unindo os dataframes de Typagem de cada imagem:\n",
    "\n",
    "print('Dataframe HAM10000: ', df_HAM10000_csv_filtered.shape)\n",
    "print('Dataframe HAM10000 colunas: ', df_HAM10000_csv_filtered.columns)\n",
    "\n",
    "print('Dataframe Med Node: ', df_mednode.shape)\n",
    "print('Dataframe Med Node colunas: ', df_mednode.columns)\n",
    "\n",
    "df_HAM10000_final=df_HAM10000_csv_filtered.drop(columns=['lesion_id', 'dx_type', 'age', 'sex', 'localization', 'dataset'])\n",
    "df_HAM10000_final=df_HAM10000_final.rename(columns = {'image_id': 'image_id', 'dx': 'type'}, inplace = False)\n",
    "\n",
    "df_final = pd.DataFrame(columns=['image_id','type'])\n",
    "df_final = df_final.append(df_HAM10000_final, ignore_index=True)\n",
    "df_final = df_final.append(df_mednode, ignore_index=True)\n",
    "\n",
    "print('Dataframe final: ' , df_final.shape)\n",
    "\n",
    "print(df_final.head())\n",
    "print(df_final.tail())\n",
    "\n",
    "df_final.to_csv(\"dataset_final//\" + \"classificacao_dataset.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Processamento/Tratamento dos Dados\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import albumentations as alb\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!cd dataset_final/imagens/ && ls"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "imagens = []\n",
    "for arquivo in os.listdir(FINAL_PATH):\n",
    "  img = cv2.imread(os.path.join(FINAL_PATH,arquivo))\n",
    "  if img is not None:\n",
    "    imagens.append(img)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Quantidade de Imagens: ', len(imagens))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "altura=[]\n",
    "largura=[]\n",
    "canal=[]\n",
    "  \n",
    "for i in range(2):\n",
    "  print(\"Imagem:\",i+1)\n",
    "  x,y,z=imagens[i].shape\n",
    "  largura.append(x)\n",
    "  altura.append(y)\n",
    "  canal.append(z)\n",
    "  print('largura: ' + str(x) + ', altura: ' + str(y) + ', canal: '+ str(z))\n",
    "  plt.imshow(imagens[i])\n",
    "  plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Análise/Exploração dos Dados\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import tensorflow as tf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from keras.utils.np_utils import to_categorical # used for converting labels to one-hot-encoding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import autokeras as ak"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pwd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pele_df = pd.read_csv('dataset_final/classificacao_dataset.csv')\n",
    "print(pele_df.head())\n",
    "np.random.seed(42)\n",
    "\n",
    "SIZE=32"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# label encoding to numeric values from text\n",
    "le = LabelEncoder()\n",
    "le.fit(pele_df['type'])\n",
    "LabelEncoder()\n",
    "print(list(le.classes_))\n",
    "print('label 0 é igual á ' + list(le.classes_)[0])\n",
    "print('label 1 é igual á ' + list(le.classes_)[1])\n",
    "\n",
    "pele_df['label'] = le.transform(pele_df[\"type\"]) \n",
    "print(pele_df.sample(10))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Data distribution visualization\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "ax = fig.add_subplot(221)\n",
    "pele_df['type'].value_counts().plot(kind='bar', ax=ax)\n",
    "ax.set_ylabel('Quantidade')\n",
    "ax.set_title('Tipo de lesão');\n",
    "ax.bar_label(ax.containers[0])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(pele_df['label'].value_counts())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "new_pele_df = pele_df.copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Distribution of data into various classes \n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "#Balance data.\n",
    "# Many ways to balance data... you can also try assigning weights during model.fit\n",
    "#Separate each classes, resample, and combine back into single dataframe\n",
    "\n",
    "df_0 = pele_df[pele_df['label'] == 0]\n",
    "df_1 = pele_df[pele_df['label'] == 1]\n",
    "\n",
    "\n",
    "n_samples=1500\n",
    "df_mel_balanceado = resample(df_0, replace=True, n_samples=n_samples, random_state=42) \n",
    "df_nv_balanceado = resample(df_1, replace=True, n_samples=n_samples, random_state=42)\n",
    "\n",
    "pele_df_balanceado = pd.concat([df_mel_balanceado, df_nv_balanceado])\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#pele_df_balanceado\n",
    "#Now time to read images based on image ID from the CSV file\n",
    "#This is the safest way to read images as it ensures the right image is read for the right ID\n",
    "print(pele_df_balanceado['label'].value_counts())\n",
    "\n",
    "image_path = {os.path.splitext(os.path.basename(x))[0]: x\n",
    "                     for x in glob(os.path.join('dataset_final', '*', '*.jpg'))}\n",
    "#Define the path and add as a new column\n",
    "pele_df_balanceado['path'] = pele_df['image_id'].map(image_path.get)\n",
    "#Use the path to read images.\n",
    "pele_df_balanceado['imagem'] = pele_df_balanceado['path'].map(lambda x: np.asarray(Image.open(x).resize((SIZE,SIZE))))\n",
    "\n",
    "pele_df_balanceado.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#pele_df_não_balanceado\n",
    "#Now time to read images based on image ID from the CSV file\n",
    "#This is the safest way to read images as it ensures the right image is read for the right ID\n",
    "print(new_pele_df['label'].value_counts())\n",
    "\n",
    "pele_df_nao_balanceado = new_pele_df.copy()\n",
    "\n",
    "image_path = {os.path.splitext(os.path.basename(x))[0]: x\n",
    "                     for x in glob(os.path.join('dataset_final', '*', '*.jpg'))}\n",
    "#Define the path and add as a new column\n",
    "pele_df_nao_balanceado['path'] = new_pele_df['image_id'].map(image_path.get)\n",
    "#Use the path to read images.\n",
    "pele_df_nao_balanceado['imagem'] = pele_df_nao_balanceado['path'].map(lambda x: np.asarray(Image.open(x).resize((SIZE,SIZE))))\n",
    "\n",
    "pele_df_nao_balanceado.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "num_exemplos = 3  \n",
    "\n",
    "# Plot\n",
    "fig, m_axs = plt.subplots(2, num_exemplos, figsize = (4*num_exemplos, 2*3))\n",
    "for n_axs, (type_name, type_rows) in zip(m_axs, \n",
    "                                         pele_df_balanceado.sort_values(['type']).groupby('type')):\n",
    "    n_axs[0].set_title(type_name)\n",
    "    for c_ax, (_, c_row) in zip(n_axs, type_rows.sample(num_exemplos, random_state=1234).iterrows()):\n",
    "        c_ax.imshow(c_row['imagem'])\n",
    "        c_ax.axis('off')\n",
    "\n",
    "fig, m_axs = plt.subplots(2, num_exemplos, figsize = (4*num_exemplos, 2*3))\n",
    "for n_axs, (type_name, type_rows) in zip(m_axs, \n",
    "                                         pele_df_nao_balanceado.sort_values(['type']).groupby('type')):\n",
    "    n_axs[0].set_title(type_name)\n",
    "    for c_ax, (_, c_row) in zip(n_axs, type_rows.sample(num_exemplos, random_state=1234).iterrows()):\n",
    "        c_ax.imshow(c_row['imagem'])\n",
    "        c_ax.axis('off')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Convert dataframe column of images into numpy array\n",
    "X_balanceado = np.asarray(pele_df_balanceado['imagem'].tolist())\n",
    "X_balanceado = X_balanceado/255. # Scale values to 0-1. You can also used standardscaler or other scaling methods.\n",
    "Y_balanceado = pele_df_balanceado['label'] #Assign label values to Y\n",
    "Y_cat_balanceado = to_categorical(Y_balanceado, num_classes=2) #Convert to categorical as this is a multiclass classification problem\n",
    "print('X_balanceado: ', X_balanceado)\n",
    "print('Y_balanceado: ', Y_balanceado)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Convert dataframe column of images into numpy array\n",
    "X = np.asarray(pele_df_nao_balanceado['imagem'].tolist())\n",
    "X = X /255. # Scale values to 0-1. You can also used standardscaler or other scaling methods.\n",
    "Y = pele_df_nao_balanceado['label'] #Assign label values to Y\n",
    "Y_cat = to_categorical(Y, num_classes=2) #Convert to categorical as this is a multiclass classification problem\n",
    "print('X: ', X)\n",
    "print('Y: ', Y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Split to training and testing. Get a very small dataset for training as we will be \n",
    "# fitting it to many potential models. \n",
    "x_train_auto_balanceado, x_test_auto_balanceado, y_train_auto_balanceado, y_test_auto_balanceado = train_test_split(X_balanceado, Y_cat_balanceado, test_size=0.80, random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.2, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip = True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "datagen.fit(x_train_auto_balanceado)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Criação do Modelo de ML"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32,3,padding=\"same\", activation=\"relu\", input_shape=(SIZE,SIZE,3)))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation=\"relu\"))\n",
    "model.add(Dense(2, activation=\"sigmoid\"))\n",
    "\n",
    "model.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.compile(\n",
    "    loss=keras.losses.sparse_categorical_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Adadelta(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "batch_size = 256\n",
    "epochs = 50"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Modelo com base balanceada\n",
    "history_balanceado  = model.fit(X_balanceado, Y_balanceado,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_split=0.2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Modelo com base não_balanceada\n",
    "history_nao_balanceado = model.fit(X, Y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_split=0.2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Interpretação dos Resultados"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Resultados base balanceada"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history_balanceado.history['accuracy'])\n",
    "plt.plot(history_balanceado.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history_balanceado.history['loss'])\n",
    "plt.plot(history_balanceado.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.evaluate(X_balanceado[-500:],Y_balanceado[-500:])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Y_pred_balanceado = model.predict(X_balanceado)\n",
    "\n",
    "yd = Y_pred_balanceado[:, 1] - Y_pred_balanceado[:, 0]\n",
    "\n",
    "most_mel = np.argsort(yd)\n",
    "most_nv = np.argsort(yd)[::-1]\n",
    "most_ambiguous = np.argsort(np.abs(yd))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.plot(np.sort(yd))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "files = [\"{}/{}\".format(FINAL_PATH, fi) for fi in os.listdir(FINAL_PATH) if fi.endswith(\"jpg\")]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_image_data(filename):\n",
    "    img = Image.open(filename)\n",
    "    img.load()\n",
    "    data = np.asarray(img, dtype=\"int32\")\n",
    "    return data\n",
    "    \n",
    "def plot_N(indices, savename=None):    \n",
    "    f, axarr = plt.subplots(len(indices) // 5, 5)\n",
    "    f.set_size_inches(14, 14)\n",
    "    f.subplots_adjust(wspace=0.2, hspace=0, left=0, right=1, top=0.4, bottom=0)\n",
    "    for i in range(len(indices)):\n",
    "        axarr[i // 5, i % 5].axis(\"off\")\n",
    "        axarr[i // 5, i % 5].imshow(get_image_data(files[indices[i]]))\n",
    "    if savename is not None:\n",
    "        f.savefig('./exported_images/' & savename)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_N(most_mel[:10], \"most_mel.jpg\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_N(most_nv[:10], \"most_nv.jpg\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_N(most_ambiguous[:30], \"most_ambiguous.jpg\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Resultados Base não balanceada"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history_nao_balanceado.history['accuracy'])\n",
    "plt.plot(history_nao_balanceado.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history_nao_balanceado.history['loss'])\n",
    "plt.plot(history_nao_balanceado.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.evaluate(X[-500:],Y[-500:])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Y_pred = model.predict(X)\n",
    "\n",
    "yd = Y_pred[:, 1] - Y_pred[:, 0]\n",
    "\n",
    "most_mel = np.argsort(yd)\n",
    "most_nv = np.argsort(yd)[::-1]\n",
    "most_ambiguous = np.argsort(np.abs(yd))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.plot(np.sort(yd))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. Comunicação dos Resultados"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 8. Referencias\n",
    "Tschandl, Philipp, 2018, \"The HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions\", https://doi.org/10.7910/DVN/DBW86T, Harvard Dataverse, V3, UNF:6:/APKSsDGVDhwPBWzsStU5A== [fileUNF]\n",
    "\n",
    "I. Giotis, N. Molders, S. Land, M. Biehl, M.F. Jonkman and N. Petkov: \"MED-NODE: A computer-assisted melanoma diagnosis system using non-dermoscopic images\", Expert Systems with Applications, 42 (2015), 6578-6585 \n",
    "\n",
    "Skin cancer detection: Applying a deep learning based model driven architecture in the cloud for classifying dermal cell images | https://www.sciencedirect.com/science/article/pii/S2352914819302047\n",
    "\n",
    "PH2 dataset | https://www.fc.up.pt/addi/ph2%20database.html\n",
    "\n",
    "\n",
    "Aprendizagem Profunda Aplicada a Identificação de melanoma | https://tedebc.ufma.br/jspui/bitstream/tede/2578/2/LucasMaia.pdf\n",
    "\n",
    "Github Project - Skin Cancer detection |\n",
    "https://github.com/Tirth27/Skin-Cancer-Classification-using-Deep-Learning\n",
    "\n",
    "Good keras gudie | https://www.analyticsvidhya.com/blog/2020/10/create-image-classification-model-python-keras/\n",
    "\n",
    "MACHINE LEARNING WITH PYTHON: TRAIN YOUR OWN IMAGE CLASSIFICATION MODEL WITH KERAS AND TENSORFLOW | https://mlconference.ai/blog/machine-learning-with-python/\n",
    "\n",
    "Single Label Imagem Classification | https://blog.workaround.vercel.app/blog/single-label-image-classification-with-keras"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}